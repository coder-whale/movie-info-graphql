{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Parser.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HC-7nJygPGpX",
        "outputId": "41ebc352-0cac-4165-9b56-4cd0771a5168"
      },
      "source": [
        "!pip install simplejson\n",
        "!pip install pymongo\n",
        "!pip install dnspython\n",
        "!pip install 'pymongo[srv]'\n",
        "\n",
        "import re\n",
        "import sys\n",
        "import json\n",
        "import simplejson\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "from pymongo import MongoClient\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.7/dist-packages (3.17.2)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (3.11.3)\n",
            "Requirement already satisfied: dnspython in /usr/local/lib/python3.7/dist-packages (1.16.0)\n",
            "Requirement already satisfied: pymongo[srv] in /usr/local/lib/python3.7/dist-packages (3.11.3)\n",
            "Requirement already satisfied: dnspython<2.0.0,>=1.16.0; extra == \"srv\" in /usr/local/lib/python3.7/dist-packages (from pymongo[srv]) (1.16.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zaJ7Cy7aNDp"
      },
      "source": [
        "#Kaggle dataset stored to drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAVLKNsAPXv1",
        "outputId": "ca33e95d-53e8-4816-a5ef-c232ff033834"
      },
      "source": [
        "!cp \"/content/drive/MyDrive/projects/PlacementSavior/bruv.zip\" \"/content/\"\n",
        "!unzip \"bruv.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  bruv.zip\n",
            "  inflating: credits.csv             \n",
            "  inflating: keywords.csv            \n",
            "  inflating: links.csv               \n",
            "  inflating: links_small.csv         \n",
            "  inflating: movies_metadata.csv     \n",
            "  inflating: ratings.csv             \n",
            "  inflating: ratings_small.csv       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xn6STLyhZ_si"
      },
      "source": [
        "# Base class \n",
        " All other classes are inherited from this, and this contains the common methods used by the rest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfFeom9ibY-Z"
      },
      "source": [
        "class BaseDataParser():\n",
        "  def __init__(self,csvPath,collectionName,dbName,mongoURI):\n",
        "    self.df = pd.read_csv(csvPath)\n",
        "    self.jsons = []\n",
        "    self.myclient = MongoClient(mongoURI)\n",
        "    self.db = self.myclient[dbName]\n",
        "    self.collection = self.db[collectionName]\n",
        "    self.columns = self.df.columns\n",
        "\n",
        "  def varIsNan(self,var):\n",
        "    return var!=var\n",
        "\n",
        "  def splicerArray(self,document,attribute,requiredSubAttribute):\n",
        "    if(self.varIsNan(document[attribute])):\n",
        "      return document[attribute]\n",
        "    splicedData = [data[requiredSubAttribute] for data in document[attribute]]\n",
        "    return splicedData\n",
        "\n",
        "  def splicerSingle(self,document,attribute,requiredSubAttribute):\n",
        "    if(self.varIsNan(document[attribute])):\n",
        "      return document[attribute]\n",
        "    return document[attribute][requiredSubAttribute]\n",
        "\n",
        "  def jsonParser(self,input):\n",
        "    try:\n",
        "      ans = eval(input)\n",
        "    except:\n",
        "      return input\n",
        "    return ans\n",
        "  \n",
        "  def renameColumn(self,json,oldColumnName,newColumnName):\n",
        "    json[newColumnName] = json.pop(oldColumnName)\n",
        "    return json\n",
        "  \n",
        "  def getSingleJson(self,index):\n",
        "    return self.jsons[index]\n",
        "\n",
        "  def removeJsonNaNs(self):\n",
        "    refinedJsons = []\n",
        "    for i in range(len(self.jsons)):\n",
        "      try:\n",
        "        item = self.jsons[i]\n",
        "        item = simplejson.dumps(self.jsons[i], indent=4, sort_keys=True,ignore_nan=True)\n",
        "        item = json.loads(item)\n",
        "        refinedJsons.append(item)\n",
        "      except Exception as e:\n",
        "        print(\"Code has run into damar: \"+str(e))\n",
        "    self.jsons = refinedJsons\n",
        "\n",
        "  def printJson(self,index):\n",
        "    print(simplejson.dumps(self.jsons[index], indent=4, sort_keys=True,ignore_nan=True))\n",
        "\n",
        "  def getAllJson(self):\n",
        "    return self.jsons\n",
        "  \n",
        "  def writeToMongo(self):\n",
        "    count = 0\n",
        "    length = len(self.jsons)\n",
        "    for item in self.jsons:\n",
        "      try:\n",
        "        self.collection.insert_one(item)\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "      count+=1\n",
        "      print(\n",
        "        '\\r',\" Percentage Uploaded \"+str(count*100/length),\n",
        "        end=''\n",
        "      )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrAvayR2brlB"
      },
      "source": [
        "class MoviesMetaDataParser(BaseDataParser):\n",
        "  def __init__(self,csvPath,collectionName,dbName,mongoURI):\n",
        "    super().__init__(csvPath,collectionName,mongoURI)\n",
        "    self.prep()\n",
        "    self.removeJsonNaNs()\n",
        "    self.writeToMongo()\n",
        "\n",
        "  def prep(self):\n",
        "    for index,row in self.df.iterrows():\n",
        "      try:\n",
        "        x = { column: self.jsonParser(row[column]) for column in self.columns}\n",
        "        \n",
        "        x['genres'] = self.splicerArray(x,'genres','id')\n",
        "        x['belongs_to_collection'] = self.splicerSingle(x,'belongs_to_collection','id')\n",
        "        x['production_companies'] = self.splicerArray(x,'production_companies','id')\n",
        "        x['production_countries'] = self.splicerArray(x,'production_countries','iso_3166_1')\n",
        "        x['spoken_languages'] = self.splicerArray(x,'spoken_languages','iso_639_1')\n",
        "        x['release_date'] = str(row['release_date'])\n",
        "\n",
        "        x = self.renameColumn(x,'genres','genre_ids')\n",
        "        x['collection_id'] = x.pop('belongs_to_collection')\n",
        "        x['production_company_ids'] = x.pop('production_companies')\n",
        "\n",
        "        self.jsons.append(x)\n",
        "      except Exception as e:\n",
        "        print(e)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FQjQ4kXQo4a"
      },
      "source": [
        "class GenreIdMappings(BaseDataParser):\n",
        "  def __init__(self,csvPath,collectionName):\n",
        "    super().__init__(csvPath,collectionName)\n",
        "    self.prep()\n",
        "    self.writeToMongo()\n",
        "\n",
        "  def prep(self):\n",
        "    self.genres = set()\n",
        "    for index,row in self.df.iterrows():\n",
        "      try:\n",
        "        x = { column: self.jsonParser(row[column]) for column in self.columns}\n",
        "        for item in x['genres']:\n",
        "          self.genres.add(simplejson.dumps(item, indent=4, sort_keys=True,ignore_nan=True))\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "    self.jsons = list(self.genres)\n",
        "    self.jsons = [simplejson.loads(item) for item in self.jsons]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZelNa6M5vuue"
      },
      "source": [
        "class ProductionCompaniesMappings(BaseDataParser):\n",
        "  def __init__(self,csvPath,collectionName):\n",
        "    super().__init__(csvPath,collectionName)\n",
        "    self.prep()\n",
        "    self.writeToMongo()\n",
        "\n",
        "  def prep(self):\n",
        "    self.genres = set()\n",
        "    for index,row in self.df.iterrows():\n",
        "      try:\n",
        "        x = { column: self.jsonParser(row[column]) for column in self.columns}\n",
        "        for item in x['production_companies']:\n",
        "          self.genres.add(simplejson.dumps(item, indent=4, sort_keys=True,ignore_nan=True))\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "    self.jsons = list(self.genres)\n",
        "    self.jsons = [simplejson.loads(item) for item in self.jsons]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLZRKq-EMjoN"
      },
      "source": [
        "class ProductionCountriesMappings(BaseDataParser):\n",
        "  def __init__(self,csvPath,collectionName):\n",
        "    super().__init__(csvPath,collectionName)\n",
        "    self.prep()\n",
        "    self.writeToMongo()\n",
        "  \n",
        "  def prep(self):\n",
        "    self.productionCountries = set()\n",
        "    for index,row in self.df.iterrows():\n",
        "      try:\n",
        "        x = { column: self.jsonParser(row[column]) for column in self.columns}\n",
        "        for item in x['production_countries']:\n",
        "          item = self.renameColumn(item,'iso_3166_1','code')\n",
        "          self.productionCountries.add(simplejson.dumps(item, indent=4, sort_keys=True,ignore_nan=True))\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "    self.jsons = list(self.productionCountries)\n",
        "    self.jsons = [simplejson.loads(item) for item in self.jsons]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMt73w-nOYPk"
      },
      "source": [
        "class SpokenLanguagesMappings(BaseDataParser):\n",
        "  def __init__(self,csvPath,collectionName):\n",
        "    super().__init__(csvPath,collectionName)\n",
        "    self.prep()\n",
        "    self.writeToMongo()\n",
        "  \n",
        "  def prep(self):\n",
        "    self.spokenLanguages = set()\n",
        "    for index,row in self.df.iterrows():\n",
        "      try:\n",
        "        x = { column: self.jsonParser(row[column]) for column in self.columns}\n",
        "        for item in x['spoken_languages']:\n",
        "          item = self.renameColumn(item,'iso_639_1','code')\n",
        "          self.spokenLanguages.add(simplejson.dumps(item, indent=4, sort_keys=True,ignore_nan=True))\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "    self.jsons = list(self.spokenLanguages)\n",
        "    self.jsons = [simplejson.loads(item) for item in self.jsons]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-ZDcZ2cQyVd"
      },
      "source": [
        "class CollectionMappings(BaseDataParser):\n",
        "  def __init__(self,csvPath,collectionName):\n",
        "    super().__init__(csvPath,collectionName)\n",
        "    self.prep()\n",
        "    self.writeToMongo()\n",
        "  \n",
        "  def prep(self):\n",
        "    self.productionCountries = set()\n",
        "    count = 0\n",
        "    for index,row in self.df.iterrows():\n",
        "      try:\n",
        "        x = { column: self.jsonParser(row[column]) for column in self.columns}\n",
        "        item = x['belongs_to_collection']\n",
        "        self.productionCountries.add(simplejson.dumps(item, indent=4, sort_keys=True,ignore_nan=True))\n",
        "      except Exception as e:\n",
        "        count+=1\n",
        "    self.jsons = list(self.productionCountries)\n",
        "    self.jsons = [simplejson.loads(item) for item in self.jsons]\n",
        "    print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "undC8XhSZ2KP"
      },
      "source": [
        "Replace the variables with your collection name, DB name and URI name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrVbe6Zbg_lI",
        "outputId": "35179de2-6a47-4a4d-a5ad-d77966702f02"
      },
      "source": [
        "moviesMetaData = MoviesMetaDataParser(\"movies_metadata.csv\",\"collection_name_here\",\"db_name_here\",\"mongo URI here\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "'float' object is not subscriptable\n",
            "'float' object is not subscriptable\n",
            "'float' object is not subscriptable\n",
            "Code has run into damar: Object of type ellipsis is not JSON serializable\n",
            "Code has run into damar: Object of type builtin_function_or_method is not JSON serializable\n",
            "Code has run into damar: Object of type builtin_function_or_method is not JSON serializable\n",
            "Code has run into damar: Object of type builtin_function_or_method is not JSON serializable\n",
            "Code has run into damar: Object of type builtin_function_or_method is not JSON serializable\n",
            "Code has run into damar: Object of type builtin_function_or_method is not JSON serializable\n",
            "Code has run into damar: Object of type builtin_function_or_method is not JSON serializable\n",
            "Code has run into damar: Object of type builtin_function_or_method is not JSON serializable\n",
            "Code has run into damar: Object of type builtin_function_or_method is not JSON serializable\n",
            "Code has run into damar: Object of type builtin_function_or_method is not JSON serializable\n",
            "Code has run into damar: Object of type builtin_function_or_method is not JSON serializable\n",
            "Code has run into damar: Object of type builtin_function_or_method is not JSON serializable\n",
            "Code has run into damar: Object of type builtin_function_or_method is not JSON serializable\n",
            "Code has run into damar: Object of type builtin_function_or_method is not JSON serializable\n",
            "Code has run into damar: Object of type builtin_function_or_method is not JSON serializable\n",
            "Code has run into damar: Object of type builtin_function_or_method is not JSON serializable\n",
            "Code has run into damar: Object of type builtin_function_or_method is not JSON serializable\n",
            "Code has run into damar: Object of type builtin_function_or_method is not JSON serializable\n",
            "Code has run into damar: Object of type builtin_function_or_method is not JSON serializable\n",
            "Code has run into damar: Object of type builtin_function_or_method is not JSON serializable\n",
            "Code has run into damar: Object of type builtin_function_or_method is not JSON serializable\n",
            "  Percentage Uploaded 100.0"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yztl4wYQtxO2"
      },
      "source": [
        "#collectionMapping = CollectionMappings('movies_metadata.csv',\"collection_name_here\",\"db_name_here\",\"mongo URI here\")\n",
        "#spokenLanguagesMapping = SpokenLanguagesMappings('movies_metadata.csv',\"collection_name_here\",\"db_name_here\",\"mongo URI here\")\n",
        "#productionCountriesMapping = ProductionCountriesMappings('movies_metadata.csv',\"collection_name_here\",\"db_name_here\",\"mongo URI here\")\n",
        "#productionCompaniesMapping = ProductionCompaniesMappings('movies_metadata.csv',\"collection_name_here\",\"db_name_here\",\"mongo URI here\")\n",
        "#genresMapping = GenreIdMappings(\"movies_metadata.csv\",\"collection_name_here\",\"db_name_here\",\"mongo URI here\")\n",
        "#moviesMetaData = MoviesMetaDataParser(\"movies_metadata.csv\",\"collection_name_here\",\"db_name_here\",\"mongo URI here\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}